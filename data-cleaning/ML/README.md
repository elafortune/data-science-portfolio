
ğŸ§  Imputation supervisÃ©e des valeurs manquantes : Year of Birth et Gender
ğŸ“‚ PrÃ©sentation du projet
Ce projet vise Ã  rÃ©soudre le problÃ¨me de valeurs manquantes dans deux colonnes clÃ©s dâ€™un jeu de donnÃ©es massif (~2 million de lignes) :

"yob" (year of birth / annÃ©e de naissance)

"gender" (genre / sexe)

PlutÃ´t que dâ€™utiliser des mÃ©thodes classiques (suppression, moyenne, mode), jâ€™ai appliquÃ© une approche dâ€™imputation supervisÃ©e en utilisant des modÃ¨les de machine learning. Chaque colonne a Ã©tÃ© traitÃ©e comme une variable cible Ã  prÃ©dire Ã  partir des autres colonnes disponibles.

ğŸ¯ Objectifs
Identifier et analyser les valeurs manquantes dans les colonnes "yob" et "gender".

Construire des modÃ¨les prÃ©dictifs pour estimer les valeurs manquantes.

IntÃ©grer les prÃ©dictions dans le jeu de donnÃ©es pour amÃ©liorer sa qualitÃ©.

ğŸ› ï¸ MÃ©thodologie
1. Exploration et nettoyage des donnÃ©es
RepÃ©rage des valeurs manquantes (yob == -1, gender == 'unknown' ou NaN).

Analyse des distributions, des corrÃ©lations, et de la qualitÃ© des features.

PrÃ©traitement : encodage des variables catÃ©gorielles, normalisation si besoin.

2. SÃ©lection des variables explicatives
SÃ©lection de variables pertinentes pour prÃ©dire "yob" et "gender".

Suppression ou transformation de variables non informatives.

3. ModÃ©lisation supervisÃ©e
Imputation de "yob" :
â¤ ModÃ¨le utilisÃ© : LightGBM Classifier
â¤ PrÃ©diction de lâ€™annÃ©e de naissance comme un problÃ¨me de classification multiclasses.

Imputation de "gender" :
â¤ ModÃ¨le utilisÃ© : Random Forest Classifier
â¤ PrÃ©diction binaire ou multiclasse du genre Ã  partir d'autres attributs.

4. Ã‰valuation des modÃ¨les
SÃ©paration entraÃ®nement / validation.

MÃ©triques utilisÃ©es : accuracy, matrice de confusion, analyse dâ€™erreur.

5. Imputation finale
PrÃ©diction des valeurs manquantes.

Remplacement dans le jeu de donnÃ©es original pour obtenir un dataset complet.

ğŸ“ˆ Technologies utilisÃ©es
Python : pandas, numpy, scikit-learn, LightGBM, matplotlib, seaborn

Jupyter Notebook : pour le dÃ©veloppement itÃ©ratif

Random Forest & LightGBM : pour lâ€™imputation supervisÃ©e

ğŸ“Š RÃ©sultats
Colonnes imputÃ©es :

yob : ~40 % de valeurs manquantes remplacÃ©es (~800 000 lignes)

gender : ~40 % de valeurs manquantes remplacÃ©es (~800 000 lignes)

Performances des modÃ¨les :

yob : prÃ©cision de ~2 % sur validation soit environ 2 fois plus que le remplissage au hasard des annÃ©es de naissances

gender : prÃ©cision de ~50 % soit Ã©galement Ã  une dÃ©termination au hasard du genre

Jeu de donnÃ©es final plus complet, cohÃ©rent et prÃªt pour lâ€™analyse ou la modÃ©lisation.

ğŸ” Enseignements clÃ©s
Lâ€™imputation supervisÃ©e permet de mieux exploiter les donnÃ©es disponibles quâ€™une approche naÃ¯ve.

Le choix des features est crucial pour obtenir des prÃ©dictions fiables.

Ce type dâ€™approche est facilement gÃ©nÃ©ralisable Ã  dâ€™autres variables avec des valeurs manquantes.

